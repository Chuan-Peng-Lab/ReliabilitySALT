---
title: "Functions"
author: "yuki"
date: "2023-03-07"
output: html_document
---
# MC SHR functions
```{r mcshrgener_st}
mcshrgener_st <- function(df.split, iteration) {
# Scientific notation
options(scipen = 999)

# MC seed
set.seed(123)

#convert data.frame to data.table
setDT(df.split)

# Stratify the data by Match and Identity
split_data <- split(df.split,list(df.split$Subject, df.split$Session,
                                   df.split$Match, df.split$Identity))

# Initialize a vector to store the Pearson correlation coefficients
split_list <- vector("list", iteration)

  for (j in 1:iteration) {
  
    # Initialize empty lists to store the split-half data sets
    str_half_split_1 <- list()
    str_half_split_2 <- list()

    # Calculate the split-half reliability for each group
    str_half_split <- lapply(split_data, function(x) {
      
      # Remove rows with missing values 
      data <- x[complete.cases(x),]

      # Permute the rows of the data and split it into two halves
      permuted_data <- data[sample(nrow(data)),]
      half_split_1 <- permuted_data[1:floor(nrow(permuted_data)/2),]
      half_split_2 <- permuted_data[(floor(nrow(permuted_data)/2)+1):nrow(permuted_data),]

      # Get the minimum number of rows between the two data sets
      min_rows <- min(nrow(half_split_1), nrow(half_split_2))

      # Subset both data sets to use the same number of rows
      half_split_1 <- half_split_1[1:min_rows,]
      half_split_2 <- half_split_2[1:min_rows,]

      # Return the split-half data sets
      return(list(half_split_1, half_split_2))
      })

  # Combine the split-half data sets from all groups
  str_half_split_1 <- do.call(rbind, lapply(str_half_split, "[[", 1))
  str_half_split_2 <- do.call(rbind, lapply(str_half_split, "[[", 2))

  split_list[[j]] <- list(str_half_split_1, str_half_split_2)

}

return(split_list)
}

```

```{r mcshrgener}
mcshrgener <- function(df.split, iteration, nc) {
  # Scientific notation
  options(scipen = 999)

  # Convert data.frame to data.table
  setDT(df.split)

  # Stratify the data by Match and Identity
  split_data <- split(df.split, list(df.split$Subject, df.split$Session, df.split$Match, df.split$Identity))

  # Initialize a vector to store the Pearson correlation coefficients
  split_list <- vector("list", iteration)

  # Initialize the parallel backend
  registerDoParallel(nc)

  # Run the for loop in parallel
  split_list <- foreach(j = 1:iteration, .combine = "c") %dopar% {
    set.seed(122+j)
    # Initialize empty lists to store the split-half data sets
    str_half_split_1 <- list()
    str_half_split_2 <- list()

    # Calculate the split-half reliability for each group
    str_half_split <- lapply(split_data, function(x) {

      # Remove rows with missing values
      data <- x[complete.cases(x),]

      # Permute the rows of the data and split it into two halves
      permuted_data <- data[sample(nrow(data)),]
      half_split_1 <- permuted_data[1:floor(nrow(permuted_data)/2),]
      half_split_2 <- permuted_data[(floor(nrow(permuted_data)/2)+1):nrow(permuted_data),]

      # Get the minimum number of rows between the two data sets
      min_rows <- min(nrow(half_split_1), nrow(half_split_2))

      # Subset both data sets to use the same number of rows
      half_split_1 <- half_split_1[1:min_rows,]
      half_split_2 <- half_split_2[1:min_rows,]

      # Return the split-half data sets
      return(list(half_split_1, half_split_2))
    })

    # Combine the split-half data sets from all groups
    str_half_split_1 <- do.call(rbind, lapply(str_half_split, "[[", 1))
    str_half_split_2 <- do.call(rbind, lapply(str_half_split, "[[", 2))

    # Return the split-half data sets
    return(list(str_half_split_1, str_half_split_2))
  }
  
  # Stop the parallel backend
  stopImplicitCluster()

  # Combine every two sublists into a single list and create a new list of length iteration
  combined_list <- vector("list", iteration)
  for (i in 1:iteration) {
    combined_list[[i]] <- list(split_list[[2*i-1]], split_list[[2*i]])
  }
  
  return(combined_list)
}

```

```{r mcshr_rt, message=FALSE}
mcshr_rt <- function(list, nc) {
  
  # Initialize the parallel backend
  registerDoParallel(nc)

  r_values <- foreach(j = 1:length(list), .packages = c("dplyr", "tidyr")) %dopar% {
    
    SPE_half_1 <- list[[j]][[1]] %>%
      dplyr::filter(., Match == "Match", ACC == "1") %>%
      dplyr::group_by(Subject, Session, Identity) %>%
      dplyr::summarise(mean_rt = mean(RT_ms)) %>%
      dplyr::ungroup() %>%
      dplyr::group_by(Subject, Session) %>%
      tidyr::pivot_wider(names_from = Identity,
                         values_from = mean_rt) %>%
      dplyr::summarise(rt_1_SPE = Self - (Stranger + Friend) / 2) %>% # mean rt of self-match - mean rt of other-match
      dplyr::ungroup() %>%
      dplyr::select(rt_1_SPE) 
    
    SPE_half_2 <- list[[j]][[2]] %>%
      dplyr::filter(., Match == "Match", ACC == "1") %>%
      dplyr::group_by(Subject, Session, Identity) %>%
      dplyr::summarise(mean_rt = mean(RT_ms)) %>%
      dplyr::ungroup() %>%
      dplyr::group_by(Subject, Session) %>%
      tidyr::pivot_wider(names_from = Identity,
                         values_from = mean_rt) %>%
      dplyr::summarise(rt_1_SPE = Self - (Stranger + Friend) / 2) %>% # mean rt of self-match - mean rt of other-match
      dplyr::ungroup() %>%
      dplyr::select(rt_1_SPE) 

    cor(SPE_half_1, SPE_half_2, method = "pearson")
  }
  
  # Stop the parallel backend
  stopImplicitCluster()

  # Calculate the mean of the Pearson correlation coefficients
  r_values_vector <- unlist(r_values)
  r <- mean(r_values_vector)
  CI <- quantile(r_values_vector, c(0.025, 0.975))

  plot.SHR.MC[1,1] <<- "RT"
  plot.SHR.MC[1,2] <<- r
  plot.SHR.MC[1,3] <<- CI[1]
  plot.SHR.MC[1,4] <<- CI[2]
  
  print(paste("Estimated Indece is Reaction Time"))
  print(paste("Monte-Carlo Split-Half Reliability:", round(r, 7)))
  print(paste("95% CI:", paste(round(CI, 7), collapse=", ")))
}

```

```{r mcshr_acc, message=FALSE}
mcshr_acc <- function(list, nc) {
  
  # Initialize the parallel backend
  registerDoParallel(nc)

  r_values <- foreach(j = 1:length(list), .packages = c("dplyr", "tidyr")) %dopar% {
    
    SPE_half_1 <- list[[j]][[1]] %>%
      dplyr::filter(.,Match == "Match") %>%   
      dplyr::group_by(Subject,Session,Identity)%>% 
      dplyr::summarise(acc = mean(ACC))%>% 
      dplyr::ungroup() %>% 
      dplyr::group_by(Subject,Session) %>%
      tidyr::pivot_wider(names_from = Identity, 
                                      values_from = acc) %>%
      dplyr::summarise(acc_SPE = Self - (Stranger + Friend)/2) %>%
      dplyr::ungroup() %>%
      dplyr::select(acc_SPE)
    
  SPE_half_2 <- list[[j]][[2]] %>%
      dplyr::filter(.,Match == "Match") %>%   
      dplyr::group_by(Subject,Session,Identity)%>% 
      dplyr::summarise(acc = mean(ACC))%>% 
      dplyr::ungroup() %>% 
      dplyr::group_by(Subject,Session) %>%
      tidyr::pivot_wider(names_from = Identity, 
                                      values_from = acc) %>%
      dplyr::summarise(acc_SPE = Self - (Stranger + Friend)/2) %>%
      dplyr::ungroup() %>%
      dplyr::select(acc_SPE)

    cor(SPE_half_1, SPE_half_2, method = "pearson")
  }
  
  # Stop the parallel backend
  stopImplicitCluster()

  # Calculate the mean of the Pearson correlation coefficients
  r_values_vector <- unlist(r_values)
  r <- mean(r_values_vector)
  CI <- quantile(r_values_vector, c(0.025, 0.975))

  plot.SHR.MC[2,1] <<- "ACC"
  plot.SHR.MC[2,2] <<- r
  plot.SHR.MC[2,3] <<- CI[1]
  plot.SHR.MC[2,4] <<- CI[2]
  
  print(paste("Estimated Indece is Accuracy"))
  print(paste("Monte-Carlo Split-Half Reliability:", round(r, 7)))
  print(paste("95% CI:", paste(round(CI, 7), collapse=", ")))
}
```

```{r mcshr_d, message=FALSE}
mcshr_d <- function(list, nc) {
  
  # Initialize the parallel backend
  registerDoParallel(nc)

  r_values <- foreach(j = 1:length(list), .packages = c("dplyr", "tidyr")) %dopar% {
    
    SPE_half_1 <- list[[j]][[1]] %>%
    dplyr::group_by(Subject,Session,Identity) %>% 
    dplyr::summarise(
      hit = length(ACC[Match == "Match" & ACC == 1]),
      fa = length(ACC[Match == "Nonmatch" & ACC == 0]),
      miss = length(ACC[Match == "Match" & ACC == 0]),
      cr = length(ACC[Match == "Nonmatch" & ACC == 1]),
      Dprime = qnorm(
        ifelse(hit / (hit + miss) < 1,
               hit / (hit + miss),
               1 - 1 / (2 * (hit + miss))
              )
           ) - qnorm(
        ifelse(fa / (fa + cr) > 0,
               fa / (fa + cr),
               1 / (2 * (fa + cr))
              )
                    )) %>% 
    dplyr::ungroup() %>%
    select(-"hit",-"fa",-"miss",-"cr") %>%
    dplyr::group_by(Subject, Session)  %>%
    tidyr::pivot_wider(names_from = Identity,
                     values_from = Dprime) %>%
    dplyr::summarise(dprime_SPE = Self - (Stranger + Friend) / 2) %>%
    dplyr::ungroup() %>%
    dplyr::select(dprime_SPE)
    
  SPE_half_2 <- list[[j]][[2]] %>%
    dplyr::group_by(Subject,Session,Identity) %>% 
    dplyr::summarise(
      hit = length(ACC[Match == "Match" & ACC == 1]),
      fa = length(ACC[Match == "Nonmatch" & ACC == 0]),
      miss = length(ACC[Match == "Match" & ACC == 0]),
      cr = length(ACC[Match == "Nonmatch" & ACC == 1]),
      Dprime = qnorm(
        ifelse(hit / (hit + miss) < 1,
               hit / (hit + miss),
               1 - 1 / (2 * (hit + miss))
              )
           ) - qnorm(
        ifelse(fa / (fa + cr) > 0,
               fa / (fa + cr),
               1 / (2 * (fa + cr))
              )
                    )) %>% 
    dplyr::ungroup() %>%
    select(-"hit",-"fa",-"miss",-"cr") %>%
    dplyr::group_by(Subject, Session)  %>%
    tidyr::pivot_wider(names_from = Identity,
                     values_from = Dprime) %>%
    dplyr::summarise(dprime_SPE = Self - (Stranger + Friend) / 2) %>%
    dplyr::ungroup() %>%
    dplyr::select(dprime_SPE)

    cor(SPE_half_1, SPE_half_2, method = "pearson")
  }
  
  # Stop the parallel backend
  stopImplicitCluster()

  # Calculate the mean of the Pearson correlation coefficients
  r_values_vector <- unlist(r_values)
  r <- mean(r_values_vector)
  CI <- quantile(r_values_vector, c(0.025, 0.975))

  plot.SHR.MC[3,1] <<- "Dprime"
  plot.SHR.MC[3,2] <<- r
  plot.SHR.MC[3,3] <<- CI[1]
  plot.SHR.MC[3,4] <<- CI[2]
  
  print(paste("Estimated Indece is d prime"))
  print(paste("Monte-Carlo Split-Half Reliability:", round(r, 7)))
  print(paste("95% CI:", paste(round(CI, 7), collapse=", ")))
}
```

```{r mcshr_eff, message=FALSE}
mcshr_eff <- function(list, nc) {
  
  # Initialize the parallel backend
  registerDoParallel(nc)

  r_values <- foreach(j = 1:length(list), .packages = c("dplyr", "tidyr")) %dopar% {
    
    SPE_half_1 <- list[[j]][[1]] %>%
    dplyr::group_by(Subject, Identity, Match, Session) %>% 
    dplyr::summarise(Eff = mean(RT_ms)/mean(ACC))%>% 
    dplyr::ungroup() %>%
    dplyr::group_by(Subject, Session) %>%
    tidyr::pivot_wider(names_from = Identity,
                       values_from = Eff) %>%
    dplyr::summarise(eff_SPE = Self - (Stranger + Friend) / 2) %>% 
    dplyr::ungroup() %>%
    dplyr::select(eff_SPE)
    
  SPE_half_2 <- list[[j]][[2]] %>%
    dplyr::group_by(Subject, Identity, Match, Session) %>% 
    dplyr::summarise(Eff = mean(RT_ms)/mean(ACC))%>% 
    dplyr::ungroup() %>%
    dplyr::group_by(Subject, Session) %>%
    tidyr::pivot_wider(names_from = Identity,
                       values_from = Eff) %>%
    dplyr::summarise(eff_SPE = Self - (Stranger + Friend) / 2) %>% 
    dplyr::ungroup() %>%
    dplyr::select(eff_SPE)

    cor(SPE_half_1, SPE_half_2, method = "pearson")
  }
  
  # Stop the parallel backend
  stopImplicitCluster()

  # Calculate the mean of the Pearson correlation coefficients
  r_values_vector <- unlist(r_values)
  r <- mean(r_values_vector)
  CI <- quantile(r_values_vector, c(0.025, 0.975))

  plot.SHR.MC[4,1] <<- "Eff"
  plot.SHR.MC[4,2] <<- r
  plot.SHR.MC[4,3] <<- CI[1]
  plot.SHR.MC[4,4] <<- CI[2]
  
  print(paste("Estimated Indece is Efficiency"))
  print(paste("Monte-Carlo Split-Half Reliability:", round(r, 7)))
  print(paste("95% CI:", paste(round(CI, 7), collapse=", ")))

}
```

```{r mcshr_ddmv, message=FALSE}
mcshr_ddmv <- function(list, nc) {
  
  # Initialize the parallel backend
  registerDoParallel(nc)

  r_values <- foreach(j = 1:length(list), .packages = c("dplyr", "tidyr", "hausekeep")) %dopar% {
    
  SPE_half_1 <- list[[j]][[1]] %>%
    hausekeep::fit_ezddm(data = ., rts = "RT_sec", responses = "ACC", id = "Subject", group = c("Session", "Match", "Identity")) %>%
    dplyr::select(Subject, Session, Match, Identity, v) %>%
    dplyr::filter(Match == "Match") %>% 
    dplyr::group_by(Subject, Session) %>% 
    tidyr::pivot_wider(names_from = Identity,
                      values_from = v) %>% 
    dplyr::summarise(v_SPE = Self - (Stranger + Friend) / 2) %>% 
    ungroup() %>%
    dplyr::select(v_SPE)
    
  SPE_half_2 <- list[[j]][[2]] %>%
    hausekeep::fit_ezddm(data = ., rts = "RT_sec", responses = "ACC", id = "Subject", group = c("Session", "Match", "Identity")) %>%
    dplyr::select(Subject, Session, Match, Identity, v) %>%
    dplyr::filter(Match == "Match") %>% 
    dplyr::group_by(Subject, Session) %>% 
    tidyr::pivot_wider(names_from = Identity,
                      values_from = v) %>% 
    dplyr::summarise(v_SPE = Self - (Stranger + Friend) / 2) %>% 
    ungroup() %>%
    dplyr::select(v_SPE)

    cor(SPE_half_1, SPE_half_2, method = "pearson")
  }
  
  # Stop the parallel backend
  stopImplicitCluster()

  # Calculate the mean of the Pearson correlation coefficients
  r_values_vector <- unlist(r_values)
  r <- mean(r_values_vector)
  CI <- quantile(r_values_vector, c(0.025, 0.975))

  plot.SHR.MC[5,1] <<- "ezDDM_v"
  plot.SHR.MC[5,2] <<- r
  plot.SHR.MC[5,3] <<- CI[1]
  plot.SHR.MC[5,4] <<- CI[2]
  
  print(paste("Estimated Indece is DDM: v"))
  print(paste("Monte-Carlo Split-Half Reliability:", round(r, 7)))
  print(paste("95% CI:", paste(round(CI, 7), collapse=", ")))
}
```

```{r mcshr_ddmz, message=FALSE}
mcshr_ddmz <- function(list, nc) {
  
  # Initialize the parallel backend
  registerDoParallel(nc)

  r_values <- foreach(j = 1:length(list), .packages = c("dplyr", "tidyr", "hausekeep")) %dopar% {
    
    SPE_half_1 <- list[[j]][[1]] %>%
      hausekeep::fit_ezddm(data = ., rts = "RT_sec", responses = "ACC", id = "Subject", group = c("Session", "Match", "Identity")) %>%
      dplyr::mutate(., z = a/v) %>%
      dplyr::select(Subject, Session, Match, Identity, z) %>%
      dplyr::filter(Match == "Match") %>% 
      dplyr::group_by(Subject, Session) %>% 
      tidyr::pivot_wider(names_from = Identity,
                         values_from = z) %>% 
      dplyr::summarise(z_SPE = Self - (Stranger + Friend) / 2) %>% 
      ungroup() %>%
      dplyr::select(z_SPE)
    
  SPE_half_2 <- list[[j]][[2]] %>%
      hausekeep::fit_ezddm(data = ., rts = "RT_sec", responses = "ACC", id = "Subject", group = c("Session", "Match", "Identity")) %>%
      dplyr::mutate(., z = a/v) %>%
      dplyr::select(Subject, Session, Match, Identity, z) %>%
      dplyr::filter(Match == "Match") %>% 
      dplyr::group_by(Subject, Session) %>% 
      tidyr::pivot_wider(names_from = Identity,
                         values_from = z) %>% 
      dplyr::summarise(z_SPE = Self - (Stranger + Friend) / 2) %>% 
      ungroup() %>%
      dplyr::select(z_SPE)

    cor(SPE_half_1, SPE_half_2, method = "pearson")
  }
  
  # Stop the parallel backend
  stopImplicitCluster()

  # Calculate the mean of the Pearson correlation coefficients
  r_values_vector <- unlist(r_values)
  r <- mean(r_values_vector)
  CI <- quantile(r_values_vector, c(0.025, 0.975))

  plot.SHR.MC[6,1] <<- "ezDDM_z"
  plot.SHR.MC[6,2] <<- r
  plot.SHR.MC[6,3] <<- CI[1]
  plot.SHR.MC[6,4] <<- CI[2]
  
  print(paste("Estimated Indece is DDM: z"))
  print(paste("Monte-Carlo Split-Half Reliability:", round(r, 7)))
  print(paste("95% CI:", paste(round(CI, 7), collapse=", ")))

}
```

```{r mcshr}
mcshr <- function(list, nc, indice) {
  if (indice == "rt") {
    result <- capture.output({mcshr_rt(list, nc)})
  } else if (indice == "acc") {
    result <- capture.output({mcshr_acc(list, nc)})
  } else if (indice == "d") {
    result <- capture.output({mcshr_d(list, nc)})
  } else if (indice == "eff") {
    result <- capture.output({mcshr_eff(list, nc)})
  } else if (indice == "ddmv") {
    result <- capture.output({mcshr_ddmv(list, nc)})
  } else if (indice == "ddmz") {
    result <- capture.output({mcshr_ddmz(list, nc)})
  } else {
    stop("Invalid indice argument")
  }
  return(result)
}
```

# Other SHR functions
```{r Split Tool}
  split_tool <- function(df.split, method) {

  # Set the seed to fix the output value
  set.seed(123)

  # Scientific notation
  options(scipen = 999)

  # Stratify the data by Match and Identity
  split_data <- split(df.split,list(df.split$Subject, df.split$Session,
                                    df.split$Match, df.split$Identity))

  # Initialize empty lists to store the split-half data sets
  str_half_split_1 <- list()
  str_half_split_2 <- list()

    # Calculate the split-half reliability for each group
    str_half_split <- lapply(split_data, function(x) {
      
      # Remove rows with missing values 
      data <- x[complete.cases(x),]

      
      if(method == "permuted") {
        # Permute the rows of the data and split it into two halves
        permuted_data <- data[sample(nrow(data)),]
        half_split_1 <- permuted_data[1:floor(nrow(permuted_data)/2),]
        half_split_2 <- permuted_data[(floor(nrow(permuted_data)/2)+1):nrow(permuted_data),]
      }
      else if(method == "fs") {
        # Split the data into two subsets using a first-second split
        half_split_1 <- data[1:floor(nrow(data)/2),]
        half_split_2 <- data[(floor(nrow(data)/2)+1):nrow(data),]  
      }
      else {
        # Create a vector of row indices
        row_indices <- seq(1, nrow(data))
        # Select the odd-numbered indices for one split-half group
        half_split_1 <- data[row_indices %% 2 == 1, ]
        # Select the even-numbered indices for the other split-half group
        half_split_2 <- data[row_indices %% 2 == 0, ]
      }
      
    # Get the minimum number of rows between the two data sets
    min_rows <- min(nrow(half_split_1), nrow(half_split_2))

    # Subset both data sets to use the same number of rows
    half_split_1 <- half_split_1[1:min_rows,]
    half_split_2 <- half_split_2[1:min_rows,]

    # Return the split-half data sets
    return(list(half_split_1, half_split_2))
      })

  # Combine the split-half data sets from all groups
  str_half_split_1 <- do.call(rbind, lapply(str_half_split, "[[", 1))
  str_half_split_2 <- do.call(rbind, lapply(str_half_split, "[[", 2))

  split_list <- list(str_half_split_1, str_half_split_2)
  
  return(split_list)
}
```

```{r shr_rt, message=FALSE}
shr_rt <- function(list) {
  for(j in 1:length(list)) {  
    SPE_half_1 <- list[[j]][[1]] %>%
      dplyr::filter(.,Match == "Match", ACC == "1") %>%
      dplyr::group_by(Subject, Session, Identity) %>%
      dplyr::summarise(mean_rt = mean(RT_ms)) %>%
      dplyr::ungroup() %>%
      dplyr::group_by(Subject, Session) %>%
      tidyr::pivot_wider(names_from = Identity,
                         values_from = mean_rt) %>%
      dplyr::summarise(rt_1_SPE = Self - (Stranger + Friend) / 2) %>% # mean rt of self-match - mean rt of other-match
      dplyr::ungroup() %>%
      dplyr::select(rt_1_SPE) 
    
    SPE_half_2 <- list[[j]][[2]] %>%
      dplyr::filter(.,Match == "Match", ACC == "1") %>%
      dplyr::group_by(Subject, Session, Identity) %>%
      dplyr::summarise(mean_rt = mean(RT_ms)) %>%
      dplyr::ungroup() %>%
      dplyr::group_by(Subject, Session) %>%
      tidyr::pivot_wider(names_from = Identity,
                         values_from = mean_rt) %>%
      dplyr::summarise(rt_1_SPE = Self - (Stranger + Friend) / 2) %>% # mean rt of self-match - mean rt of other-match
      dplyr::ungroup() %>%
      dplyr::select(rt_1_SPE) 
    
      r_value <- cor(SPE_half_1, SPE_half_2, method = "pearson")


    df.SHR.Other[j,1] <<- "RT"
    df.SHR.Other[j,3] <<- r_value
  }
}
```

```{r shr_acc, message=FALSE}
shr_acc <- function(list) {
  for(j in 1:length(list)) {  
      SPE_half_1 <- list[[j]][[1]] %>%
        dplyr::filter(.,Match == "Match") %>%   
        dplyr::group_by(Subject,Session,Identity)%>% 
        dplyr::summarise(acc = mean(ACC))%>% 
        dplyr::ungroup() %>% 
        dplyr::group_by(Subject,Session) %>%
        tidyr::pivot_wider(names_from = Identity, 
                                        values_from = acc) %>%
        dplyr::summarise(acc_SPE = Self - (Stranger + Friend)/2) %>%
        dplyr::ungroup() %>%
        dplyr::select(acc_SPE)
    
    SPE_half_2 <- list[[j]][[2]] %>%
        dplyr::filter(.,Match == "Match") %>%   
        dplyr::group_by(Subject,Session,Identity)%>% 
        dplyr::summarise(acc = mean(ACC))%>% 
        dplyr::ungroup() %>% 
        dplyr::group_by(Subject,Session) %>%
        tidyr::pivot_wider(names_from = Identity, 
                                      values_from = acc) %>%
        dplyr::summarise(acc_SPE = Self - (Stranger + Friend)/2) %>%
        dplyr::ungroup() %>%
        dplyr::select(acc_SPE)
    
      r_value <- cor(SPE_half_1, SPE_half_2, method = "pearson")


    df.SHR.Other[j+3,1] <<- "ACC"
    df.SHR.Other[j+3,3] <<- r_value
  }
}
```

```{r shr_d, message=FALSE}
shr_d <- function(list) {
  for(j in 1:length(list)) {  
    SPE_half_1 <- list[[j]][[1]] %>%
    dplyr::group_by(Subject,Session,Identity) %>% 
    dplyr::summarise(
      hit = length(ACC[Match == "Match" & ACC == 1]),
      fa = length(ACC[Match == "Nonmatch" & ACC == 0]),
      miss = length(ACC[Match == "Match" & ACC == 0]),
      cr = length(ACC[Match == "Nonmatch" & ACC == 1]),
      Dprime = qnorm(
        ifelse(hit / (hit + miss) < 1,
               hit / (hit + miss),
               1 - 1 / (2 * (hit + miss))
              )
           ) - qnorm(
        ifelse(fa / (fa + cr) > 0,
               fa / (fa + cr),
               1 / (2 * (fa + cr))
              )
                    )) %>% 
    dplyr::ungroup() %>%
    select(-"hit",-"fa",-"miss",-"cr") %>%
    dplyr::group_by(Subject, Session)  %>%
    tidyr::pivot_wider(names_from = Identity,
                     values_from = Dprime) %>%
    dplyr::summarise(dprime_SPE = Self - (Stranger + Friend) / 2) %>%
    dplyr::ungroup() %>%
    dplyr::select(dprime_SPE)
    
  SPE_half_2 <- list[[j]][[2]] %>%
    dplyr::group_by(Subject,Session,Identity) %>% 
    dplyr::summarise(
      hit = length(ACC[Match == "Match" & ACC == 1]),
      fa = length(ACC[Match == "Nonmatch" & ACC == 0]),
      miss = length(ACC[Match == "Match" & ACC == 0]),
      cr = length(ACC[Match == "Nonmatch" & ACC == 1]),
      Dprime = qnorm(
        ifelse(hit / (hit + miss) < 1,
               hit / (hit + miss),
               1 - 1 / (2 * (hit + miss))
              )
           ) - qnorm(
        ifelse(fa / (fa + cr) > 0,
               fa / (fa + cr),
               1 / (2 * (fa + cr))
              )
                    )) %>% 
    dplyr::ungroup() %>%
    select(-"hit",-"fa",-"miss",-"cr") %>%
    dplyr::group_by(Subject, Session)  %>%
    tidyr::pivot_wider(names_from = Identity,
                     values_from = Dprime) %>%
    dplyr::summarise(dprime_SPE = Self - (Stranger + Friend) / 2) %>%
    dplyr::ungroup() %>%
    dplyr::select(dprime_SPE)
    
    r_value <- cor(SPE_half_1, SPE_half_2, method = "pearson")


  df.SHR.Other[j+6,1] <<- "Dprime"
  df.SHR.Other[j+6,3] <<- r_value
  }
}
```

```{r shr_eff, message=FALSE}
shr_eff <- function(list) {
  for(j in 1:length(list)) {  
      SPE_half_1 <- list[[j]][[1]] %>%
      dplyr::group_by(Subject, Identity, Match, Session) %>% 
      dplyr::summarise(Eff = mean(RT_ms)/mean(ACC))%>% 
      dplyr::ungroup() %>%
      dplyr::group_by(Subject, Session) %>%
      tidyr::pivot_wider(names_from = Identity,
                         values_from = Eff) %>%
      dplyr::summarise(eff_SPE = Self - (Stranger + Friend) / 2) %>% 
      dplyr::ungroup() %>%
      dplyr::select(eff_SPE)
    
    SPE_half_2 <- list[[j]][[2]] %>%
      dplyr::group_by(Subject, Identity, Match, Session) %>% 
      dplyr::summarise(Eff = mean(RT_ms)/mean(ACC))%>% 
      dplyr::ungroup() %>%
      dplyr::group_by(Subject, Session) %>%
      tidyr::pivot_wider(names_from = Identity,
                       values_from = Eff) %>%
      dplyr::summarise(eff_SPE = Self - (Stranger + Friend) / 2) %>% 
      dplyr::ungroup() %>%
      dplyr::select(eff_SPE)
    
      r_value <- cor(SPE_half_1, SPE_half_2, method = "pearson")


    df.SHR.Other[j+9,1] <<- "Efficiency"
    df.SHR.Other[j+9,3] <<- r_value
}
  
}
```

```{r SHR.Other of DDM: v, message=FALSE}
shr_ddmv <- function(list) {
  for(j in 1:length(list)) {  
    SPE_half_1 <- list[[j]][[1]] %>%
      hausekeep::fit_ezddm(data = ., rts = "RT_sec", responses = "ACC", id = "Subject", group = c("Session", "Match", "Identity")) %>%
      dplyr::select(Subject, Session, Match, Identity, v) %>%
      dplyr::filter(Match == "Match") %>% 
      dplyr::group_by(Subject, Session) %>% 
      tidyr::pivot_wider(names_from = Identity,
                         values_from = v) %>% 
      dplyr::summarise(v_SPE = Self - (Stranger + Friend) / 2) %>% 
      ungroup() %>%
      dplyr::select(v_SPE)
    
    SPE_half_2 <- list[[j]][[2]] %>%
      hausekeep::fit_ezddm(data = ., rts = "RT_sec", responses = "ACC", id = "Subject", group = c("Session", "Match", "Identity")) %>%
      dplyr::select(Subject, Session, Match, Identity, v) %>%
      dplyr::filter(Match == "Match") %>% 
      dplyr::group_by(Subject, Session) %>% 
      tidyr::pivot_wider(names_from = Identity,
                         values_from = v) %>% 
      dplyr::summarise(v_SPE = Self - (Stranger + Friend) / 2) %>% 
      ungroup() %>%
      dplyr::select(v_SPE)
    
      r_value <- cor(SPE_half_1, SPE_half_2, method = "pearson")


    df.SHR.Other[j+12,1] <<- "DDM: v"
    df.SHR.Other[j+12,3] <<- r_value
  }
}
```

```{r SHR.Other of DDM: z, message=FALSE}
shr_ddmz <- function(list) {
  for(j in 1:length(list)) {  
    SPE_half_1 <- list[[j]][[1]] %>%
        hausekeep::fit_ezddm(data = ., rts = "RT_sec", responses = "ACC", id = "Subject", group = c("Session", "Match", "Identity")) %>%
        dplyr::mutate(., z = a/v) %>%
        dplyr::select(Subject, Session, Match, Identity, z) %>%
        dplyr::filter(Match == "Match") %>% 
        dplyr::group_by(Subject, Session) %>% 
        tidyr::pivot_wider(names_from = Identity,
                           values_from = z) %>% 
        dplyr::summarise(z_SPE = Self - (Stranger + Friend) / 2) %>% 
        ungroup() %>%
        dplyr::select(z_SPE)
    
    SPE_half_2 <- list[[j]][[2]] %>%
        hausekeep::fit_ezddm(data = ., rts = "RT_sec", responses = "ACC", id = "Subject", group = c("Session", "Match", "Identity")) %>%
        dplyr::mutate(., z = a/v) %>%
        dplyr::select(Subject, Session, Match, Identity, z) %>%
        dplyr::filter(Match == "Match") %>% 
        dplyr::group_by(Subject, Session) %>% 
        tidyr::pivot_wider(names_from = Identity,
                           values_from = z) %>% 
        dplyr::summarise(z_SPE = Self - (Stranger + Friend) / 2) %>% 
        ungroup() %>%
        dplyr::select(z_SPE)
    
      r_value <- cor(SPE_half_1, SPE_half_2, method = "pearson")


    df.SHR.Other[j+15,1] <<- "DDM: z"
    df.SHR.Other[j+15,3] <<- r_value
  }
}
```

```{r shr}
shr <- function(list, indice) {
  if (indice == "rt") {
    result <- capture.output({shr_rt(list)})
  } else if (indice == "acc") {
    result <- capture.output({shr_acc(list)})
  } else if (indice == "d") {
    result <- capture.output({shr_d(list)})
  } else if (indice == "eff") {
    result <- capture.output({shr_eff(list)})
  } else if (indice == "ddmv") {
    result <- capture.output({shr_ddmv(list)})
  } else if (indice == "ddmz") {
    result <- capture.output({shr_ddmz(list)})
  } else {
    stop("Invalid indice argument")
  }
  return(result)
}
```

# ICC 
```{r ICC_calculation}
ICC_calculation <- function(SPE_ICC) {
  ICC_output <- lapply(SPE_ICC, function(x) {psych::ICC(x, lmer = FALSE)})
  ICC_result <- list()
  for (i in 1:length(ICC_output)){
    ICC_result[[i]] <- ICC_output[[i]][[1]]
  }
  ICC_result_final <- rbindlist(ICC_result) 
  colnames(ICC_result_final)[7] <- "LLCI"
  colnames(ICC_result_final)[8] <- "ULCI"
  ICC_result_final$ICC_type <- rep(c("RT","ACC",
                                     "Dprime","Efficiency",
                                     "ezDDM_v","ezDDM_z"), 
                                     each = nrow(ICC_result_final)/6)
  
  colnames(ICC_result_final)[7] <- "LLCI"
  colnames(ICC_result_final)[8] <- "ULCI"
  ICC_result_final <- ICC_result_final %>%
    dplyr::mutate(.,ICC_type = factor(ICC_type, 
                                      levels = c("RT","ACC",
                                                 "Dprime","Efficiency",
                                                 "ezDDM_v","ezDDM_z")) ) %>%
    dplyr::arrange(.,type) %>%
    dplyr::select(type, ICC_type, ICC, LLCI, ULCI) 
  return(ICC_result_final)
}
```




